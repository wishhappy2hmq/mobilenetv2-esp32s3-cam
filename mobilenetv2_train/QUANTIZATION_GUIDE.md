# MobileNetV2 模型量化指南

## 概述

本指南将帮助你将训练好的 MobileNetV2 ONNX 模型量化为 ESP32 可用的 ESPDL 格式。

## 量化流程

### 步骤 1: 安装必要的工具包

安装 ESP-PPQ (ESP32 专用的量化工具)：

```bash
# 安装 esp-ppq
pip install esp-ppq

# 如果上面的命令失败，尝试从源码安装
pip install git+https://github.com/espressif/esp-ppq.git
```

其他依赖：
```bash
pip install onnx onnxruntime torch torchvision
```

### 步骤 2: 准备校准数据集

量化需要一个**校准数据集 (Calibration Dataset)**，用于统计模型各层的激活值分布。

**要求：**
- 从训练集或验证集中选择有代表性的样本
- 通常需要 500-1000 张图片
- 图片应该包含各种场景（有人脸和无人脸）

**建议目录结构：**
```
calib_data/
  ├── pos/  # 有图像的样本 (约500张)
  └── nag/  # 无图像的样本 (约500张)
```

### 步骤 3: 修改量化脚本

我已经为你创建了一个适配的量化脚本 `quantize_my_model.py`，主要修改：

1. **输入尺寸**：从 224x224 改为 320x320
2. **ONNX 路径**：指向你的训练好的模型
3. **校准数据集路径**：指向你的数据集
4. **目标平台**：选择 ESP32-S3 或 ESP32-P4

### 步骤 4: 运行量化

```bash
python quantize_my_model.py
```

### 步骤 5: 验证量化模型

量化后会生成 `.espdl` 文件，这是 ESP32 可以直接加载的量化模型。

## 量化选项说明

### 1. 默认量化 (Default Quantization)
- 最简单的方式，适合大多数情况
- 8-bit 整数量化

### 2. 层级均衡量化 (Layerwise Equalization)
- 如果默认量化精度损失较大，可以使用此方法
- 通过权重均衡来减少量化误差
- 需要将 ReLU6 替换为 ReLU

### 3. 混合精度量化 (Mixed Precision)
- 对精度损失大的层使用 16-bit 量化
- 其他层使用 8-bit 量化
- 可以在精度和性能之间取得平衡

## 目标平台选择

- **ESP32-S3**: 较旧的芯片，AI 加速有限
- **ESP32-P4**: 新款芯片，有专用的 AI 加速器，推荐使用

## 注意事项

1. **图像尺寸**：确保量化时的输入尺寸与训练时一致 (320x320)
2. **归一化参数**：必须与训练时相同 (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
3. **校准数据**：数据越有代表性，量化精度越高
4. **精度评估**：量化后要在验证集上测试精度，确保损失在可接受范围内

## 常见问题

### Q1: 量化后精度下降太多怎么办？
- 尝试使用 Layerwise Equalization 量化
- 尝试使用 Mixed Precision 量化
- 增加校准数据集的大小和多样性

### Q2: 量化需要多长时间？
- 通常 5-15 分钟，取决于模型大小和校准数据量

### Q3: 生成的 .espdl 文件如何使用？
- 这个文件可以直接部署到 ESP32 设备上
- 使用 ESP-DL 库加载和推理

## 下一步

量化完成后，你需要：
1. 在 ESP32 设备上集成 ESP-DL 库
2. 加载 .espdl 模型文件
3. 进行推理测试
